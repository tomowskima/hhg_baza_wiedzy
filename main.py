"""
RAG System Backend - FastAPI z OpenAI i ChromaDB
System do analizy dokument√≥w PDF z u≈ºyciem RAG z stuff dla kompendium
ver. 10 - HR Edition z MMR Search
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import List, Optional
from contextlib import asynccontextmanager
import json
import os
from datetime import datetime
from collections import defaultdict
import hashlib
import logging
from dotenv import load_dotenv
import openai
import fcntl
import time

# Workaround dla problemu z proxies w openai 1.40.0 + langchain-openai
# Problem jest w SyncHttpxClientWrapper i AsyncHttpxClientWrapper, wiƒôc patchujemy oba
try:
    from openai._base_client import SyncHttpxClientWrapper, AsyncHttpxClientWrapper
    
    # Patch dla SyncHttpxClientWrapper (OpenAI)
    _original_sync_wrapper_init = SyncHttpxClientWrapper.__init__
    def _patched_sync_wrapper_init(self, *args, **kwargs):
        kwargs.pop('proxies', None)
        return _original_sync_wrapper_init(self, *args, **kwargs)
    SyncHttpxClientWrapper.__init__ = _patched_sync_wrapper_init
    
    # Patch dla AsyncHttpxClientWrapper (AsyncOpenAI)
    _original_async_wrapper_init = AsyncHttpxClientWrapper.__init__
    def _patched_async_wrapper_init(self, *args, **kwargs):
        kwargs.pop('proxies', None)
        return _original_async_wrapper_init(self, *args, **kwargs)
    AsyncHttpxClientWrapper.__init__ = _patched_async_wrapper_init
except (ImportError, AttributeError):
    # Fallback: patchujemy bezpo≈õrednio OpenAI i AsyncOpenAI
    _original_openai_init = openai.OpenAI.__init__
    def _patched_openai_init(self, *args, **kwargs):
        kwargs.pop('proxies', None)
        return _original_openai_init(self, *args, **kwargs)
    openai.OpenAI.__init__ = _patched_openai_init
    
    _original_async_openai_init = openai.AsyncOpenAI.__init__
    def _patched_async_openai_init(self, *args, **kwargs):
        kwargs.pop('proxies', None)
        return _original_async_openai_init(self, *args, **kwargs)
    openai.AsyncOpenAI.__init__ = _patched_async_openai_init

# Import dla RAG
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# ≈Åadowanie zmiennych ≈õrodowiskowych
load_dotenv()

# Konfiguracja logowania
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Globalna instancja systemu RAG
rag_system = None

# ==================== Inicjalizacja przy starcie aplikacji ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ZarzƒÖdza cyklem ≈ºycia aplikacji - inicjalizuje RAG przy starcie"""
    global rag_system
    # Startup
    try:
        logger.info("Inicjalizacja systemu RAG przy starcie aplikacji...")
        rag_system = RAGSystem()
        logger.info("‚úÖ System RAG zainicjalizowany")
    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd inicjalizacji RAG: {e}", exc_info=True)
        logger.error("Sprawd≈∫ czy masz klucz API w zmiennych ≈õrodowiskowych")
        # Nie przerywamy startu aplikacji - pozwalamy na dzia≈Çanie bez RAG
    
    yield
    
    # Shutdown (opcjonalnie - cleanup)

app = FastAPI(
    title="RAG System API", 
    version="2.0.0",
    lifespan=lifespan
)

# CORS - pozwala na komunikacjƒô z frontendem
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # W produkcji zmie≈Ñ na konkretnƒÖ domenƒô
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== Konfiguracja ====================

# Sprawdzenie klucza API
if not os.getenv("OPENAI_API_KEY"):
    logger.error("Brak klucza OPENAI_API_KEY w pliku .env!")
    raise ValueError("Ustaw OPENAI_API_KEY w pliku .env")

# Konfiguracja folder√≥w i parametr√≥w
PDF_FOLDER = os.getenv("PDF_FOLDER", "documents/")
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", 500))  # Zmniejszone dla lepszego map_reduce
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", 100))
MAX_SEARCH_RESULTS = int(os.getenv("MAX_SEARCH_RESULTS", 8))  # Wiƒôcej fragment√≥w
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
CHAIN_TYPE = os.getenv("CHAIN_TYPE", "stuff")

# ==================== Modele danych ====================

class Question(BaseModel):
    question: str

class Answer(BaseModel):
    answer: str
    updated_faq: bool = False
    sources: List[str] = []

class FAQItem(BaseModel):
    question: str
    answer: str
    count: int
    last_asked: str
    question_hash: str

# ==================== System RAG z Stuff dla Kompendium ====================

class RAGSystem:
    def __init__(self):
        self.vectorstore = None
        self.qa_chain = None
        self.embeddings = None
        self.llm = None
        self.initialize()

    def initialize(self):
        """Inicjalizacja systemu RAG"""
        logger.info("Inicjalizacja systemu RAG - HR Edition dla kompendium...")

        # Inicjalizacja modeli OpenAI
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY nie jest ustawione w .env")
            
            # Ustaw zmiennƒÖ ≈õrodowiskowƒÖ dla OpenAI (langchain-openai czyta z env)
            os.environ["OPENAI_API_KEY"] = api_key
            
            # Workaround dla problemu z proxies w openai 1.40.0 + langchain-openai
            # Usuwamy zmienne ≈õrodowiskowe zwiƒÖzane z proxy, kt√≥re mogƒÖ powodowaƒá problem
            proxy_vars = ["HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy", "ALL_PROXY", "all_proxy"]
            for var in proxy_vars:
                if var in os.environ:
                    del os.environ[var]
            
            # Inicjalizacja embeddings - u≈ºywamy tylko zmiennej ≈õrodowiskowej
            self.embeddings = OpenAIEmbeddings(
                model=os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            )

            self.llm = ChatOpenAI(
                model=OPENAI_MODEL,
                temperature=0.1,  # Niska temperatura dla dok≈Çadno≈õci
                max_tokens=1000  # Wiƒôcej token√≥w dla map_reduce
            )
        except Exception as e:
            logger.error(f"B≈ÇƒÖd inicjalizacji OpenAI: {e}")
            raise

        # Sprawd≈∫ czy istnieje baza wektorowa
        if os.path.exists(CHROMA_PERSIST_DIR):
            logger.info("≈Åadowanie istniejƒÖcej bazy wektorowej...")
            self.load_vectorstore()
        else:
            logger.info("Tworzenie nowej bazy wektorowej...")
            self.create_vectorstore()

        # Utworzenie ≈Ça≈Ñcucha QA z map_reduce
        self.create_qa_chain()

    def create_vectorstore(self):
        """Tworzy nowƒÖ bazƒô wektorowƒÖ z dokument√≥w PDF"""

        # Sprawd≈∫ czy folder z dokumentami istnieje
        if not os.path.exists(PDF_FOLDER):
            os.makedirs(PDF_FOLDER)
            logger.warning(f"Utworzono folder {PDF_FOLDER} - dodaj pliki PDF!")
            self.vectorstore = None
            return

        # Sprawd≈∫ czy sƒÖ jakie≈õ PDFy
        pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith('.pdf')]
        if not pdf_files:
            logger.warning(f"Brak plik√≥w PDF w folderze {PDF_FOLDER}")
            self.vectorstore = None
            return

        logger.info(f"Znaleziono {len(pdf_files)} plik√≥w PDF")

        # Za≈Çaduj ka≈ºdy PDF osobno
        all_chunks = []
        for pdf_file in pdf_files:
            pdf_path = os.path.join(PDF_FOLDER, pdf_file)
            try:
                loader = PyPDFLoader(pdf_path)
                pages = loader.load()
                logger.info(f"‚úÖ Za≈Çadowano: {pdf_file} ({len(pages)} stron)")

                # Podziel na mniejsze fragmenty
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=CHUNK_SIZE,
                    chunk_overlap=CHUNK_OVERLAP,
                    length_function=len,
                    separators=["\n\n", "\n", ". ", ";", " "]
                )

                chunks = text_splitter.split_documents(pages)
                all_chunks.extend(chunks)

            except Exception as e:
                logger.error(f"‚ùå B≈ÇƒÖd ≈Çadowania {pdf_file}: {e}")
                continue

        logger.info(f"Za≈Çadowano ≈ÇƒÖcznie {len(all_chunks)} fragment√≥w")

        if all_chunks:
            self.vectorstore = Chroma.from_documents(
                documents=all_chunks,
                embedding=self.embeddings,
                persist_directory=CHROMA_PERSIST_DIR
            )
            # W nowszych wersjach langchain_chroma nie ma potrzeby wywo≈Çywania persist()
            logger.info("‚úÖ Baza wektorowa utworzona i zapisana")
        else:
            logger.warning("Brak fragment√≥w do indeksowania")
            self.vectorstore = None

    def load_vectorstore(self):
        """≈Åaduje istniejƒÖcƒÖ bazƒô wektorowƒÖ"""
        self.vectorstore = Chroma(
            persist_directory=CHROMA_PERSIST_DIR,
            embedding_function=self.embeddings
        )
        logger.info("Baza wektorowa za≈Çadowana")

    def create_qa_chain(self):
        """Tworzy ≈Ça≈Ñcuch pytanie-odpowied≈∫ z stuff dla kompendium ca≈Çej wiedzy"""
        
        if not self.vectorstore:
            logger.warning("Brak bazy wektorowej - u≈ºywam trybu mock")
            self.qa_chain = None
            return

        # Polski prompt dostosowany do dokument√≥w HR z lepszymi zasadami dla kompendium
        prompt_template = """Jeste≈õ ekspertem HR analizujƒÖcym dokumenty o procesach rekrutacji, zatrudniania i zarzƒÖdzania personelem.
        Twoim zadaniem jest stworzenie KOMPENDIUM ca≈Çej wiedzy na zadane pytanie.
        
        WA≈ªNE ZASADY:
        1. Je≈õli pytanie dotyczy CZASU - odpowiedz o czasie (w dniach/tygodniach/miesiƒÖcach)
        2. Je≈õli pytanie dotyczy KWOT - odpowiedz o kwotach (w PLN/EUR/USD)
        3. Je≈õli pytanie dotyczy PROCENT√ìW - odpowiedz o procentach (w %)
        4. Je≈õli pytanie dotyczy ETAP√ìW - wymie≈Ñ wszystkie etapy procesu
        5. Je≈õli pytanie dotyczy WYMAGA≈É - wymie≈Ñ wszystkie wymagania
        6. Je≈õli pytanie dotyczy DOKUMENT√ìW - wymie≈Ñ wszystkie potrzebne dokumenty
        7. Je≈õli pytanie dotyczy PRAW - odpowiedz zgodnie z przepisami prawa pracy
        8. Je≈õli nie znajdziesz dok≈Çadnej odpowiedzi w kontek≈õcie, napisz "Nie znalaz≈Çem tej informacji w dokumentach"
        9. BƒÖd≈∫ WYCZERPUJƒÑCY i SZCZEG√ì≈ÅOWY - nie skracaj odpowiedzi!
        10. Cytuj dok≈Çadne warto≈õci je≈õli sƒÖ podane w dokumentach
        11. U≈ºywaj TYLKO informacji z kontekstu
        12. Stw√≥rz pe≈Çny obraz tematu - kompendium ca≈Çej wiedzy
        
        Kontekst:
        {context}
        
        Pytanie: {question}
        
        KOMPENDIUM CA≈ÅEJ WIEDZY (bƒÖd≈∫ szczeg√≥≈Çowy i wyczerpujƒÖcy):"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )

        # Utw√≥rz ≈Ça≈Ñcuch QA z stuff ale z lepszymi ustawieniami dla kompendium
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_type="mmr",  # Maximum Marginal Relevance - lepsze wyniki
                search_kwargs={"k": MAX_SEARCH_RESULTS, "fetch_k": MAX_SEARCH_RESULTS * 2}
            ),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )

        logger.info(f"≈Åa≈Ñcuch QA - HR Edition (kompendium) utworzony")

    def search(self, question: str) -> dict:
        """Wyszukuje odpowied≈∫ na pytanie u≈ºywajƒÖc HR Edition dla kompendium ca≈Çej wiedzy"""

        if not self.qa_chain:
            # Tryb mock je≈õli nie ma dokument√≥w
            return {
                "answer": "System RAG nie jest jeszcze skonfigurowany. Dodaj dokumenty PDF do folderu 'documents/' i zrestartuj serwer.",
                "sources": []
            }

        try:
            # Wykonaj zapytanie
            result = self.qa_chain.invoke({"query": question})

            # Wyodrƒôbnij ≈∫r√≥d≈Ça
            sources = []
            if "source_documents" in result:
                for doc in result["source_documents"]:
                    source = doc.metadata.get("source", "").replace("\\", "/")
                    source = os.path.basename(source)
                    if source and source not in sources:
                        sources.append(source)

            return {
                "answer": result["result"],
                "sources": sources
            }

        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas wyszukiwania: {e}", exc_info=True)
            return {
                "answer": f"WystƒÖpi≈Ç b≈ÇƒÖd podczas przetwarzania pytania: {str(e)}",
                "sources": []
            }

    def reset_database(self):
        """Resetuje bazƒô wektorowƒÖ"""
        import shutil

        if os.path.exists(CHROMA_PERSIST_DIR):
            shutil.rmtree(CHROMA_PERSIST_DIR)
            logger.info("Baza wektorowa usuniƒôta")

        self.initialize()
        logger.info("Baza wektorowa zresetowana")

# ==================== Przechowywanie danych FAQ ====================

FAQ_FILE = "faq_data.json"
MAX_FAQ_ITEMS = 9

def load_faq_data():
    """≈Åaduje dane FAQ z pliku z blokadƒÖ"""
    if os.path.exists(FAQ_FILE):
        max_retries = 5
        retry_delay = 0.1
        for attempt in range(max_retries):
            try:
                with open(FAQ_FILE, 'r', encoding='utf-8') as f:
                    fcntl.flock(f.fileno(), fcntl.LOCK_SH)  # Shared lock (read)
                    try:
                        data = json.load(f)
                        logger.debug(f"üìñ FAQ za≈Çadowane z {FAQ_FILE}, liczba pyta≈Ñ: {len(data)}")
                        return data
                    finally:
                        fcntl.flock(f.fileno(), fcntl.LOCK_UN)  # Unlock
            except (IOError, OSError) as e:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                logger.error(f"‚ùå B≈ÇƒÖd odczytu FAQ z {FAQ_FILE} po {max_retries} pr√≥bach: {e}")
                return {}
            except Exception as e:
                logger.error(f"‚ùå B≈ÇƒÖd odczytu FAQ z {FAQ_FILE}: {e}")
                return {}
    else:
        logger.debug(f"üìñ Plik {FAQ_FILE} nie istnieje, zwracam pusty s≈Çownik")
    return {}

def save_faq_data(data):
    """Zapisuje dane FAQ do pliku z blokadƒÖ"""
    max_retries = 5
    retry_delay = 0.1
    for attempt in range(max_retries):
        try:
            with open(FAQ_FILE, 'w', encoding='utf-8') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)  # Exclusive lock (write)
                try:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                    f.flush()  # Wymu≈õ zapis do dysku
                    os.fsync(f.fileno())  # Synchronizuj z systemem plik√≥w
                    logger.info(f"‚úÖ FAQ zapisane do {FAQ_FILE}, liczba pyta≈Ñ: {len(data)}")
                    return
                finally:
                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)  # Unlock
        except (IOError, OSError) as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 2
                continue
            logger.error(f"‚ùå B≈ÇƒÖd zapisu FAQ do {FAQ_FILE} po {max_retries} pr√≥bach: {e}", exc_info=True)
            raise
        except Exception as e:
            logger.error(f"‚ùå B≈ÇƒÖd zapisu FAQ do {FAQ_FILE}: {e}", exc_info=True)
            raise

def get_question_hash(question: str) -> str:
    """Tworzy hash pytania dla identyfikacji podobnych pyta≈Ñ"""
    normalized = question.lower().strip()
    normalized = ''.join(c for c in normalized if c.isalnum() or c.isspace())
    normalized = ' '.join(normalized.split())
    return hashlib.md5(normalized.encode()).hexdigest()

def update_faq(question: str, answer: str) -> bool:
    """Aktualizuje FAQ i zwraca True je≈õli lista FAQ siƒô zmieni≈Ça"""
    faq_data = load_faq_data()
    question_hash = get_question_hash(question)
    
    logger.info(f"üìù Aktualizacja FAQ: pytanie='{question[:50]}...', hash={question_hash}")
    logger.info(f"üìä Za≈Çadowane FAQ: {len(faq_data)} pyta≈Ñ, klucze: {list(faq_data.keys())[:3]}...")
    logger.info(f"üîç Szukam hash '{question_hash}' w FAQ: {question_hash in faq_data}")

    if question_hash in faq_data:
        faq_data[question_hash]['count'] += 1
        faq_data[question_hash]['last_asked'] = datetime.now().isoformat()
        old_position = get_faq_position(faq_data, question_hash)
        logger.info(f"‚úÖ FAQ zaktualizowane: count={faq_data[question_hash]['count']}, pozycja={old_position}")
    else:
        faq_data[question_hash] = {
            'question': question,
            'answer': answer[:200] + "..." if len(answer) > 200 else answer,
            'count': 1,
            'last_asked': datetime.now().isoformat(),
            'question_hash': question_hash
        }
        old_position = None
        logger.info(f"‚úÖ Nowe FAQ dodane: count=1")

    sorted_items = sorted(
        faq_data.items(),
        key=lambda x: x[1]['count'],
        reverse=True
    )

    if len(sorted_items) > MAX_FAQ_ITEMS:
        items_to_keep = dict(sorted_items[:MAX_FAQ_ITEMS])
        # Sprawd≈∫ czy nowe pytanie jest w top 9
        if question_hash not in items_to_keep:
            logger.warning(f"‚ö†Ô∏è Nowe pytanie (hash={question_hash}) zosta≈Ço usuniƒôte, bo ma count=1 i jest poza top {MAX_FAQ_ITEMS}")
        faq_data = items_to_keep
    else:
        faq_data = dict(sorted_items)
    
    logger.info(f"üíæ Zapisujƒô {len(faq_data)} pyta≈Ñ, hash '{question_hash}' w danych: {question_hash in faq_data}")
    save_faq_data(faq_data)

    new_position = get_faq_position(faq_data, question_hash)
    return old_position != new_position

def get_faq_position(faq_data: dict, question_hash: str) -> Optional[int]:
    """Zwraca pozycjƒô pytania w FAQ"""
    sorted_items = sorted(
        faq_data.items(),
        key=lambda x: x[1]['count'],
        reverse=True
    )
    for i, (hash_key, _) in enumerate(sorted_items):
        if hash_key == question_hash:
            return i
    return None

# ==================== Endpointy API ====================

@app.get("/")
async def root():
    """Serwuje stronƒô HTML je≈õli istnieje, w przeciwnym razie zwraca info o API"""
    if os.path.exists("index.html"):
        with open("index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())

    return {
        "name": "RAG System API - HR Edition dla kompendium",
        "version": "2.0.0",
        "status": "ready" if rag_system else "initializing",
        "chain_type": CHAIN_TYPE,
        "endpoints": {
            "POST /api/question": "Zadaj pytanie systemowi RAG",
            "GET /api/faq": "Pobierz listƒô najczƒô≈õciej zadawanych pyta≈Ñ",
            "GET /health": "Sprawd≈∫ status systemu",
            "POST /api/reset": "Resetuj bazƒô wektorowƒÖ"
        }
    }

@app.get("/health")
async def health_check():
    """Sprawdzenie statusu systemu"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "rag_ready": rag_system is not None,
        "model": OPENAI_MODEL,
        "chain_type": CHAIN_TYPE,
        "documents_folder": PDF_FOLDER
    }

@app.post("/api/question", response_model=Answer)
async def ask_question(question: Question):
    """Endpoint do zadawania pyta≈Ñ systemowi RAG"""
    try:
        if not question.question or len(question.question.strip()) < 3:
            raise HTTPException(status_code=400, detail="Pytanie jest zbyt kr√≥tkie")

        if len(question.question) > 1000:
            raise HTTPException(status_code=400, detail="Pytanie jest zbyt d≈Çugie (max 1000 znak√≥w)")

        # Sprawd≈∫ czy system RAG jest zainicjalizowany
        if rag_system is None:
            raise HTTPException(
                status_code=503, 
                detail="System RAG nie jest jeszcze gotowy. Sprawd≈∫ logi aplikacji."
            )

        # Pobierz odpowied≈∫ z systemu RAG
        result = rag_system.search(question.question)

        # Aktualizuj FAQ
        faq_updated = update_faq(question.question, result["answer"])

        return Answer(
            answer=result["answer"],
            updated_faq=faq_updated,
            sources=result["sources"]
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas przetwarzania pytania: {e}", exc_info=True)
        logger.error(f"Typ b≈Çƒôdu: {type(e).__name__}")
        logger.error(f"Traceback: {e.__traceback__}")
        raise HTTPException(status_code=500, detail=f"B≈ÇƒÖd podczas przetwarzania pytania: {str(e)}")

@app.get("/api/faq", response_model=List[FAQItem])
async def get_faq():
    """Pobiera listƒô najczƒô≈õciej zadawanych pyta≈Ñ"""
    try:
        faq_data = load_faq_data()
        logger.debug(f"üìä GET /api/faq: za≈Çadowano {len(faq_data)} pyta≈Ñ z pliku")

        sorted_items = sorted(
            faq_data.values(),
            key=lambda x: x['count'],
            reverse=True
        )

        faq_list = []
        for item in sorted_items[:MAX_FAQ_ITEMS]:
            faq_list.append(FAQItem(**item))
        
        logger.info(f"üìä GET /api/faq: zwracam {len(faq_list)} pyta≈Ñ (max {MAX_FAQ_ITEMS})")
        return faq_list

    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas pobierania FAQ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="B≈ÇƒÖd wewnƒôtrzny serwera")

@app.get("/api/faq/debug")
async def get_faq_debug():
    """Endpoint debugowy do sprawdzenia zawarto≈õci FAQ"""
    try:
        faq_data = load_faq_data()
        file_exists = os.path.exists(FAQ_FILE)
        file_size = os.path.getsize(FAQ_FILE) if file_exists else 0
        
        return {
            "file_exists": file_exists,
            "file_path": os.path.abspath(FAQ_FILE),
            "file_size": file_size,
            "faq_count": len(faq_data),
            "faq_data": faq_data,
            "writable": os.access(FAQ_FILE if file_exists else ".", os.W_OK)
        }
    except Exception as e:
        logger.error(f"B≈ÇƒÖd w /api/faq/debug: {e}", exc_info=True)
        return {"error": str(e)}

@app.post("/api/reset")
async def reset_database():
    """Resetuje bazƒô wektorowƒÖ i przetwarza dokumenty od nowa"""
    try:
        rag_system.reset_database()
        return {"status": "success", "message": "Baza wektorowa zosta≈Ça zresetowana"}
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas resetowania: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/reset-faq")
async def reset_faq():
    """Resetuje system kafelk√≥w FAQ - usuwa wszystkie zapisane pytania"""
    try:
        if os.path.exists(FAQ_FILE):
            os.remove(FAQ_FILE)
            logger.info("Plik FAQ zosta≈Ç usuniƒôty")
        return {"status": "success", "message": "System kafelk√≥w FAQ zosta≈Ç zresetowany"}
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas resetowania FAQ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Uruchomienie ====================

if __name__ == "__main__":
    import uvicorn
    import sys

    print("=" * 60)
    print("üöÄ Uruchamianie systemu RAG - HR Edition dla kompendium...")
    print("=" * 60)

    # Sprawd≈∫ argumenty CLI
    if "--reset-db" in sys.argv:
        print("üîÑ Resetowanie bazy wektorowej...")
        if os.path.exists(CHROMA_PERSIST_DIR):
            import shutil
            shutil.rmtree(CHROMA_PERSIST_DIR)
            print("‚úÖ Baza wektorowa usuniƒôta")

    # Inicjalizacja systemu RAG
    try:
        rag_system = RAGSystem()
        print("‚úÖ System RAG - HR Edition dla kompendium zainicjalizowany")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd inicjalizacji RAG: {e}")
        print("Sprawd≈∫ czy masz klucz API w pliku .env")
        sys.exit(1)

    print("=" * 60)
    print("üìù Frontend: http://localhost:8000")
    print("üìö API Docs: http://localhost:8000/docs")
    print(f"üîó Typ ≈Ça≈Ñcucha: {CHAIN_TYPE}")
    print("=" * 60)

    # Uruchom serwer
    uvicorn.run(app, host="0.0.0.0", port=8000)