"""
RAG System Backend - FastAPI z OpenAI i ChromaDB
System do analizy dokument√≥w PDF z u≈ºyciem RAG z stuff dla kompendium
ver. 10 - HR Edition z MMR Search
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import List, Optional
import json
import os
from datetime import datetime
from collections import defaultdict
import hashlib
import logging
from dotenv import load_dotenv

# Import dla RAG
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# ≈Åadowanie zmiennych ≈õrodowiskowych
load_dotenv()

# Konfiguracja logowania
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="RAG System API", version="2.0.0")

# CORS - pozwala na komunikacjƒô z frontendem
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # W produkcji zmie≈Ñ na konkretnƒÖ domenƒô
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== Konfiguracja ====================

# Sprawdzenie klucza API
if not os.getenv("OPENAI_API_KEY"):
    logger.error("Brak klucza OPENAI_API_KEY w pliku .env!")
    raise ValueError("Ustaw OPENAI_API_KEY w pliku .env")

# Konfiguracja folder√≥w i parametr√≥w
PDF_FOLDER = os.getenv("PDF_FOLDER", "documents/")
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", 500))  # Zmniejszone dla lepszego map_reduce
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", 100))
MAX_SEARCH_RESULTS = int(os.getenv("MAX_SEARCH_RESULTS", 8))  # Wiƒôcej fragment√≥w
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
CHAIN_TYPE = os.getenv("CHAIN_TYPE", "stuff")

# ==================== Modele danych ====================

class Question(BaseModel):
    question: str

class Answer(BaseModel):
    answer: str
    updated_faq: bool = False
    sources: List[str] = []

class FAQItem(BaseModel):
    question: str
    answer: str
    count: int
    last_asked: str
    question_hash: str

# ==================== System RAG z Stuff dla Kompendium ====================

class RAGSystem:
    def __init__(self):
        self.vectorstore = None
        self.qa_chain = None
        self.embeddings = None
        self.llm = None
        self.initialize()

    def initialize(self):
        """Inicjalizacja systemu RAG"""
        logger.info("Inicjalizacja systemu RAG - HR Edition dla kompendium...")

        # Inicjalizacja modeli OpenAI
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY nie jest ustawione w .env")
            
            # Ustaw zmiennƒÖ ≈õrodowiskowƒÖ dla OpenAI (langchain-openai czyta z env)
            os.environ["OPENAI_API_KEY"] = api_key
            
            self.embeddings = OpenAIEmbeddings(
                model=os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            )

            self.llm = ChatOpenAI(
                model=OPENAI_MODEL,
                temperature=0.1,  # Niska temperatura dla dok≈Çadno≈õci
                max_tokens=1000  # Wiƒôcej token√≥w dla map_reduce
            )
        except Exception as e:
            logger.error(f"B≈ÇƒÖd inicjalizacji OpenAI: {e}")
            raise

        # Sprawd≈∫ czy istnieje baza wektorowa
        if os.path.exists(CHROMA_PERSIST_DIR):
            logger.info("≈Åadowanie istniejƒÖcej bazy wektorowej...")
            self.load_vectorstore()
        else:
            logger.info("Tworzenie nowej bazy wektorowej...")
            self.create_vectorstore()

        # Utworzenie ≈Ça≈Ñcucha QA z map_reduce
        self.create_qa_chain()

    def create_vectorstore(self):
        """Tworzy nowƒÖ bazƒô wektorowƒÖ z dokument√≥w PDF"""

        # Sprawd≈∫ czy folder z dokumentami istnieje
        if not os.path.exists(PDF_FOLDER):
            os.makedirs(PDF_FOLDER)
            logger.warning(f"Utworzono folder {PDF_FOLDER} - dodaj pliki PDF!")
            return

        # Sprawd≈∫ czy sƒÖ jakie≈õ PDFy
        pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith('.pdf')]
        if not pdf_files:
            logger.warning(f"Brak plik√≥w PDF w folderze {PDF_FOLDER}")
            return

        logger.info(f"Znaleziono {len(pdf_files)} plik√≥w PDF")

        # Za≈Çaduj ka≈ºdy PDF osobno
        all_chunks = []
        for pdf_file in pdf_files:
            pdf_path = os.path.join(PDF_FOLDER, pdf_file)
            try:
                loader = PyPDFLoader(pdf_path)
                pages = loader.load()
                logger.info(f"‚úÖ Za≈Çadowano: {pdf_file} ({len(pages)} stron)")

                # Podziel na mniejsze fragmenty
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=CHUNK_SIZE,
                    chunk_overlap=CHUNK_OVERLAP,
                    length_function=len,
                    separators=["\n\n", "\n", ". ", ";", " "]
                )

                chunks = text_splitter.split_documents(pages)
                all_chunks.extend(chunks)

            except Exception as e:
                logger.error(f"‚ùå B≈ÇƒÖd ≈Çadowania {pdf_file}: {e}")
                continue

        logger.info(f"Za≈Çadowano ≈ÇƒÖcznie {len(all_chunks)} fragment√≥w")

        if all_chunks:
            self.vectorstore = Chroma.from_documents(
                documents=all_chunks,
                embedding=self.embeddings,
                persist_directory=CHROMA_PERSIST_DIR
            )
            # W nowszych wersjach langchain_chroma nie ma potrzeby wywo≈Çywania persist()
            logger.info("‚úÖ Baza wektorowa utworzona i zapisana")
        else:
            logger.warning("Brak fragment√≥w do indeksowania")

    def load_vectorstore(self):
        """≈Åaduje istniejƒÖcƒÖ bazƒô wektorowƒÖ"""
        self.vectorstore = Chroma(
            persist_directory=CHROMA_PERSIST_DIR,
            embedding_function=self.embeddings
        )
        logger.info("Baza wektorowa za≈Çadowana")

    def create_qa_chain(self):
        """Tworzy ≈Ça≈Ñcuch pytanie-odpowied≈∫ z stuff dla kompendium ca≈Çej wiedzy"""
        
        if not self.vectorstore:
            logger.warning("Brak bazy wektorowej - u≈ºywam trybu mock")
            return

        # Polski prompt dostosowany do dokument√≥w HR z lepszymi zasadami dla kompendium
        prompt_template = """Jeste≈õ ekspertem HR analizujƒÖcym dokumenty o procesach rekrutacji, zatrudniania i zarzƒÖdzania personelem.
        Twoim zadaniem jest stworzenie KOMPENDIUM ca≈Çej wiedzy na zadane pytanie.
        
        WA≈ªNE ZASADY:
        1. Je≈õli pytanie dotyczy CZASU - odpowiedz o czasie (w dniach/tygodniach/miesiƒÖcach)
        2. Je≈õli pytanie dotyczy KWOT - odpowiedz o kwotach (w PLN/EUR/USD)
        3. Je≈õli pytanie dotyczy PROCENT√ìW - odpowiedz o procentach (w %)
        4. Je≈õli pytanie dotyczy ETAP√ìW - wymie≈Ñ wszystkie etapy procesu
        5. Je≈õli pytanie dotyczy WYMAGA≈É - wymie≈Ñ wszystkie wymagania
        6. Je≈õli pytanie dotyczy DOKUMENT√ìW - wymie≈Ñ wszystkie potrzebne dokumenty
        7. Je≈õli pytanie dotyczy PRAW - odpowiedz zgodnie z przepisami prawa pracy
        8. Je≈õli nie znajdziesz dok≈Çadnej odpowiedzi w kontek≈õcie, napisz "Nie znalaz≈Çem tej informacji w dokumentach"
        9. BƒÖd≈∫ WYCZERPUJƒÑCY i SZCZEG√ì≈ÅOWY - nie skracaj odpowiedzi!
        10. Cytuj dok≈Çadne warto≈õci je≈õli sƒÖ podane w dokumentach
        11. U≈ºywaj TYLKO informacji z kontekstu
        12. Stw√≥rz pe≈Çny obraz tematu - kompendium ca≈Çej wiedzy
        
        Kontekst:
        {context}
        
        Pytanie: {question}
        
        KOMPENDIUM CA≈ÅEJ WIEDZY (bƒÖd≈∫ szczeg√≥≈Çowy i wyczerpujƒÖcy):"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )

        # Utw√≥rz ≈Ça≈Ñcuch QA z stuff ale z lepszymi ustawieniami dla kompendium
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_type="mmr",  # Maximum Marginal Relevance - lepsze wyniki
                search_kwargs={"k": MAX_SEARCH_RESULTS, "fetch_k": MAX_SEARCH_RESULTS * 2}
            ),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )

        logger.info(f"≈Åa≈Ñcuch QA - HR Edition (kompendium) utworzony")

    def search(self, question: str) -> dict:
        """Wyszukuje odpowied≈∫ na pytanie u≈ºywajƒÖc HR Edition dla kompendium ca≈Çej wiedzy"""

        if not self.qa_chain:
            # Tryb mock je≈õli nie ma dokument√≥w
            return {
                "answer": "System RAG nie jest jeszcze skonfigurowany. Dodaj dokumenty PDF do folderu 'documents/' i zrestartuj serwer.",
                "sources": []
            }

        try:
            # Wykonaj zapytanie
            result = self.qa_chain({"query": question})

            # Wyodrƒôbnij ≈∫r√≥d≈Ça
            sources = []
            if "source_documents" in result:
                for doc in result["source_documents"]:
                    source = doc.metadata.get("source", "").replace("\\", "/")
                    source = os.path.basename(source)
                    if source and source not in sources:
                        sources.append(source)

            return {
                "answer": result["result"],
                "sources": sources
            }

        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas wyszukiwania: {e}")
            return {
                "answer": f"WystƒÖpi≈Ç b≈ÇƒÖd podczas przetwarzania pytania: {str(e)}",
                "sources": []
            }

    def reset_database(self):
        """Resetuje bazƒô wektorowƒÖ"""
        import shutil

        if os.path.exists(CHROMA_PERSIST_DIR):
            shutil.rmtree(CHROMA_PERSIST_DIR)
            logger.info("Baza wektorowa usuniƒôta")

        self.initialize()
        logger.info("Baza wektorowa zresetowana")

# Globalna instancja systemu RAG
rag_system = None

# ==================== Przechowywanie danych FAQ ====================

FAQ_FILE = "faq_data.json"
MAX_FAQ_ITEMS = 9

def load_faq_data():
    """≈Åaduje dane FAQ z pliku"""
    if os.path.exists(FAQ_FILE):
        try:
            with open(FAQ_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_faq_data(data):
    """Zapisuje dane FAQ do pliku"""
    with open(FAQ_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_question_hash(question: str) -> str:
    """Tworzy hash pytania dla identyfikacji podobnych pyta≈Ñ"""
    normalized = question.lower().strip()
    normalized = ''.join(c for c in normalized if c.isalnum() or c.isspace())
    normalized = ' '.join(normalized.split())
    return hashlib.md5(normalized.encode()).hexdigest()

def update_faq(question: str, answer: str) -> bool:
    """Aktualizuje FAQ i zwraca True je≈õli lista FAQ siƒô zmieni≈Ça"""
    faq_data = load_faq_data()
    question_hash = get_question_hash(question)

    if question_hash in faq_data:
        faq_data[question_hash]['count'] += 1
        faq_data[question_hash]['last_asked'] = datetime.now().isoformat()
        old_position = get_faq_position(faq_data, question_hash)
    else:
        faq_data[question_hash] = {
            'question': question,
            'answer': answer[:200] + "..." if len(answer) > 200 else answer,
            'count': 1,
            'last_asked': datetime.now().isoformat(),
            'question_hash': question_hash
        }
        old_position = None

    sorted_items = sorted(
        faq_data.items(),
        key=lambda x: x[1]['count'],
        reverse=True
    )

    if len(sorted_items) > MAX_FAQ_ITEMS:
        items_to_keep = dict(sorted_items[:MAX_FAQ_ITEMS])
        faq_data = items_to_keep
    else:
        faq_data = dict(sorted_items)

    save_faq_data(faq_data)

    new_position = get_faq_position(faq_data, question_hash)
    return old_position != new_position

def get_faq_position(faq_data: dict, question_hash: str) -> Optional[int]:
    """Zwraca pozycjƒô pytania w FAQ"""
    sorted_items = sorted(
        faq_data.items(),
        key=lambda x: x[1]['count'],
        reverse=True
    )
    for i, (hash_key, _) in enumerate(sorted_items):
        if hash_key == question_hash:
            return i
    return None

# ==================== Endpointy API ====================

@app.get("/")
async def root():
    """Serwuje stronƒô HTML je≈õli istnieje, w przeciwnym razie zwraca info o API"""
    if os.path.exists("index.html"):
        with open("index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())

    return {
        "name": "RAG System API - HR Edition dla kompendium",
        "version": "2.0.0",
        "status": "ready" if rag_system else "initializing",
        "chain_type": CHAIN_TYPE,
        "endpoints": {
            "POST /api/question": "Zadaj pytanie systemowi RAG",
            "GET /api/faq": "Pobierz listƒô najczƒô≈õciej zadawanych pyta≈Ñ",
            "GET /health": "Sprawd≈∫ status systemu",
            "POST /api/reset": "Resetuj bazƒô wektorowƒÖ"
        }
    }

@app.get("/health")
async def health_check():
    """Sprawdzenie statusu systemu"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "rag_ready": rag_system is not None,
        "model": OPENAI_MODEL,
        "chain_type": CHAIN_TYPE,
        "documents_folder": PDF_FOLDER
    }

@app.post("/api/question", response_model=Answer)
async def ask_question(question: Question):
    """Endpoint do zadawania pyta≈Ñ systemowi RAG"""
    try:
        if not question.question or len(question.question.strip()) < 3:
            raise HTTPException(status_code=400, detail="Pytanie jest zbyt kr√≥tkie")

        if len(question.question) > 1000:
            raise HTTPException(status_code=400, detail="Pytanie jest zbyt d≈Çugie (max 1000 znak√≥w)")

        # Pobierz odpowied≈∫ z systemu RAG
        result = rag_system.search(question.question)

        # Aktualizuj FAQ
        faq_updated = update_faq(question.question, result["answer"])

        return Answer(
            answer=result["answer"],
            updated_faq=faq_updated,
            sources=result["sources"]
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas przetwarzania pytania: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/faq", response_model=List[FAQItem])
async def get_faq():
    """Pobiera listƒô najczƒô≈õciej zadawanych pyta≈Ñ"""
    try:
        faq_data = load_faq_data()

        sorted_items = sorted(
            faq_data.values(),
            key=lambda x: x['count'],
            reverse=True
        )

        faq_list = []
        for item in sorted_items[:MAX_FAQ_ITEMS]:
            faq_list.append(FAQItem(**item))

        return faq_list

    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas pobierania FAQ: {e}")
        raise HTTPException(status_code=500, detail="B≈ÇƒÖd wewnƒôtrzny serwera")

@app.post("/api/reset")
async def reset_database():
    """Resetuje bazƒô wektorowƒÖ i przetwarza dokumenty od nowa"""
    try:
        rag_system.reset_database()
        return {"status": "success", "message": "Baza wektorowa zosta≈Ça zresetowana"}
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas resetowania: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/reset-faq")
async def reset_faq():
    """Resetuje system kafelk√≥w FAQ - usuwa wszystkie zapisane pytania"""
    try:
        if os.path.exists(FAQ_FILE):
            os.remove(FAQ_FILE)
            logger.info("Plik FAQ zosta≈Ç usuniƒôty")
        return {"status": "success", "message": "System kafelk√≥w FAQ zosta≈Ç zresetowany"}
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas resetowania FAQ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Uruchomienie ====================

if __name__ == "__main__":
    import uvicorn
    import sys

    print("=" * 60)
    print("üöÄ Uruchamianie systemu RAG - HR Edition dla kompendium...")
    print("=" * 60)

    # Sprawd≈∫ argumenty CLI
    if "--reset-db" in sys.argv:
        print("üîÑ Resetowanie bazy wektorowej...")
        if os.path.exists(CHROMA_PERSIST_DIR):
            import shutil
            shutil.rmtree(CHROMA_PERSIST_DIR)
            print("‚úÖ Baza wektorowa usuniƒôta")

    # Inicjalizacja systemu RAG
    try:
        rag_system = RAGSystem()
        print("‚úÖ System RAG - HR Edition dla kompendium zainicjalizowany")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd inicjalizacji RAG: {e}")
        print("Sprawd≈∫ czy masz klucz API w pliku .env")
        sys.exit(1)

    print("=" * 60)
    print("üìù Frontend: http://localhost:8000")
    print("üìö API Docs: http://localhost:8000/docs")
    print(f"üîó Typ ≈Ça≈Ñcucha: {CHAIN_TYPE}")
    print("=" * 60)

    # Uruchom serwer
    uvicorn.run(app, host="0.0.0.0", port=8000)